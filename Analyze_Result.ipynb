{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Firstly, calculating the average results of 10-flods. <br>\n",
    "##### Then, we choose three index to analyze results, including delta, UB and IoU. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PL_List = [\"S1\",\"S2\",\"T1\",\"T2\",\"M0\"]\n",
    "part_List = [\"01F\",\"01M\",\"02F\",\"02M\",\"03F\",\"03M\",\"04F\",\"04M\",\"05F\",\"05M\"]\n",
    "mode_List = [\"Interflow\", \"Synchro\"]\n",
    "class_nums2path = {1:\"Baseline\", 2:\"2-Cross\", 3:\"3-Cross\", 4:\"4-Cross\", 5:\"5-Cross\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal combination done! total 31 combinations.\n"
     ]
    }
   ],
   "source": [
    "def Cal_Combination(iter_index=0, Comb_List=[]):\n",
    "    if iter_index >= len(PL_List):\n",
    "        if Comb_List!=[]:\n",
    "            Combination.append(Comb_List)\n",
    "        return\n",
    "    # not contain index element\n",
    "    Cal_Combination(iter_index+1, Comb_List[:])\n",
    "    # contain index element\n",
    "    Comb_List_Next = Comb_List[:]\n",
    "    Comb_List_Next.append(PL_List[iter_index])\n",
    "    Cal_Combination(iter_index+1, Comb_List_Next[:])\n",
    "\n",
    "Combination = []\n",
    "Cal_Combination()\n",
    "print(\"cal combination done! total\",len(Combination),\"combinations.\")\n",
    "Combination.sort(key=lambda x: len(x))\n",
    "# print(Combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average&Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Interflow #######################\n",
      "M0 :\t 78.91 + 2.35\n",
      "T2 :\t 68.0 + 3.58\n",
      "T1 :\t 70.02 + 2.21\n",
      "S2 :\t 73.59 + 3.25\n",
      "S1 :\t 76.62 + 3.29\n",
      "T2M0 :\t 77.01 + 2.6\n",
      "T1M0 :\t 79.86 + 3.32\n",
      "T1T2 :\t 70.3 + 2.63\n",
      "S2M0 :\t 80.36 + 2.6\n",
      "S2T2 :\t 76.04 + 2.01\n",
      "S2T1 :\t 77.99 + 2.89\n",
      "S1M0 :\t 80.73 + 2.46\n",
      "S1T2 :\t 76.51 + 2.07\n",
      "S1T1 :\t 78.96 + 3.35\n",
      "S1S2 :\t 78.55 + 3.16\n",
      "T1T2M0 :\t 77.51 + 2.24\n",
      "S2T2M0 :\t 82.42 + 2.29\n",
      "S2T1M0 :\t 82.5 + 2.51\n",
      "S2T1T2 :\t 77.49 + 1.94\n",
      "S1T2M0 :\t 82.23 + 2.15\n",
      "S1T1M0 :\t 82.45 + 2.39\n",
      "S1T1T2 :\t 77.38 + 2.16\n",
      "S1S2M0 :\t 81.19 + 2.72\n",
      "S1S2T2 :\t 81.2 + 2.44\n",
      "S1S2T1 :\t 81.15 + 2.53\n",
      "S2T1T2M0 :\t 82.91 + 2.33\n",
      "S1T1T2M0 :\t 82.65 + 2.37\n",
      "S1S2T2M0 :\t 83.28 + 2.2\n",
      "S1S2T1M0 :\t 83.28 + 2.28\n",
      "S1S2T1T2 :\t 82.39 + 2.27\n",
      "S1S2T1T2M0 :\t 83.84 + 2.13\n",
      "####################### Synchro #######################\n",
      "M0 :\t 78.91 + 2.35\n",
      "T2 :\t 68.0 + 3.58\n",
      "T1 :\t 70.02 + 2.21\n",
      "S2 :\t 73.59 + 3.25\n",
      "S1 :\t 76.62 + 3.29\n",
      "T2M0 :\t 74.28 + 3.3\n",
      "T1M0 :\t 79.1 + 3.34\n",
      "T1T2 :\t 69.44 + 2.92\n",
      "S2M0 :\t 79.37 + 2.72\n",
      "S2T2 :\t 74.26 + 2.7\n",
      "S2T1 :\t 77.06 + 2.78\n",
      "S1M0 :\t 79.78 + 2.59\n",
      "S1T2 :\t 74.11 + 2.47\n",
      "S1T1 :\t 78.45 + 3.44\n",
      "S1S2 :\t 77.31 + 3.25\n",
      "T1T2M0 :\t 75.97 + 2.28\n",
      "S2T2M0 :\t 81.05 + 2.19\n",
      "S2T1M0 :\t 81.25 + 2.61\n",
      "S2T1T2 :\t 76.15 + 1.78\n",
      "S1T2M0 :\t 81.0 + 2.21\n",
      "S1T1M0 :\t 81.47 + 2.89\n",
      "S1T1T2 :\t 76.06 + 2.0\n",
      "S1S2M0 :\t 79.7 + 3.09\n",
      "S1S2T2 :\t 79.69 + 2.55\n",
      "S1S2T1 :\t 79.94 + 2.75\n",
      "S2T1T2M0 :\t 80.91 + 2.14\n",
      "S1T1T2M0 :\t 80.94 + 2.49\n",
      "S1S2T2M0 :\t 81.59 + 2.6\n",
      "S1S2T1M0 :\t 81.33 + 2.65\n",
      "S1S2T1T2 :\t 80.79 + 2.26\n",
      "S1S2T1T2M0 :\t 81.98 + 2.51\n"
     ]
    }
   ],
   "source": [
    "# process one mode\n",
    "for mode in mode_List:\n",
    "    print(\"#######################\",mode,\"#######################\")\n",
    "    # process one combination\n",
    "    for PL_List in Combination:\n",
    "        root_path_List = [\"./Logs/\"+part+\"/Analyze/\"+mode+\"/\"+class_nums2path[len(PL_List)]+\"/\" for part in part_List]\n",
    "        PLs = \"\".join(PL_List)\n",
    "        result_List = []\n",
    "        for root_path in root_path_List:\n",
    "            path = root_path+PLs+\"_acc.txt\"\n",
    "            df_acc = pd.read_csv(path)\n",
    "            if mode == \"Interflow\":\n",
    "                result_List.append(df_acc.iloc[-1].to_numpy()[0])\n",
    "            if mode == \"Synchro\":\n",
    "                result_List.append(df_acc.sort_values(by=[\"acc\"]).iloc[-1].to_numpy()[0])\n",
    "        result_average = np.mean(result_List)\n",
    "        result_std = np.std(result_List)\n",
    "        print(PLs,\":\\t\",round(result_average,2),\"+\",round(result_std,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UB&IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_id2str = {1:\"01F\",2:\"01M\",3:\"02F\",4:\"02M\",5:\"03F\",6:\"03M\",7:\"04F\",8:\"04M\",9:\"05F\",10:\"05M\"}\n",
    "part_id = 10\n",
    "PL_Log_Dict = {\n",
    "        \"S1\":\"2022-04-25_11-02\",\n",
    "        \"S2\":\"2022-04-25_21-14\",\n",
    "        \"T1\":\"2022-04-26_07-23\",\n",
    "        \"T2\":\"2022-04-26_06-20\",\n",
    "        \"M0\":\"2022-04-24_21-47\",\n",
    "        }\n",
    "PL_Set_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load label done! total 597 samples.\n"
     ]
    }
   ],
   "source": [
    "label2id = {'e0': 0, 'e1': 1, 'e2': 2, 'e3': 3}\n",
    "label_path = \"./Data/iemocap/iemocap_\"+part_id2str[part_id]+\".test.csv\"\n",
    "label = np.array(pd.read_csv(label_path)[\"emotion\"].map(lambda emo: label2id[emo]).values)\n",
    "print(\"load label done! total\",len(label),\"samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PL Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLset: {'S1': array([64, 97, 94, 62]), 'S2': array([82, 76, 79, 80]), 'T1': array([31, 96, 10, 35]), 'T2': array([57, 39, 60, 23]), 'M0': array([27, 97, 96, 75])}\n"
     ]
    }
   ],
   "source": [
    "PL_epoch_dict = {}\n",
    "# PLset epoch index\n",
    "for PL in PL_List:\n",
    "    path = \"./Logs/\"+part_id2str[part_id]+\"/\"+PL+\"/\"+PL_Log_Dict[PL]+\"_dev_acc.txt\"\n",
    "    df_acc = pd.read_csv(path, header=None)\n",
    "    df_acc.columns = [\"acc\"]\n",
    "    df_acc.sort_values(by=[\"acc\"], inplace=True, ascending=False)\n",
    "    PL_epoch_dict[PL] = df_acc.index.to_numpy()[:4]\n",
    "print(\"PLset:\",PL_epoch_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2M0 :\t 534 \t 89.45 %\t 63.48 %\n",
      "T1M0 :\t 537 \t 89.95 %\t 67.23 %\n",
      "T1T2 :\t 493 \t 82.58 %\t 69.57 %\n",
      "S2M0 :\t 541 \t 90.62 %\t 68.95 %\n",
      "S2T2 :\t 537 \t 89.95 %\t 58.66 %\n",
      "S2T1 :\t 545 \t 91.29 %\t 61.47 %\n",
      "S1M0 :\t 530 \t 88.78 %\t 70.75 %\n",
      "S1T2 :\t 525 \t 87.94 %\t 61.14 %\n",
      "S1T1 :\t 536 \t 89.78 %\t 62.69 %\n",
      "S1S2 :\t 513 \t 85.93 %\t 71.93 %\n",
      "T1T2M0 :\t 556 \t 93.13 %\t 53.24 %\n",
      "S2T2M0 :\t 571 \t 95.64 %\t 49.21 %\n",
      "S2T1M0 :\t 572 \t 95.81 %\t 51.57 %\n",
      "S2T1T2 :\t 560 \t 93.8 %\t 49.11 %\n",
      "S1T2M0 :\t 564 \t 94.47 %\t 51.06 %\n",
      "S1T1M0 :\t 569 \t 95.31 %\t 53.25 %\n",
      "S1T1T2 :\t 554 \t 92.8 %\t 49.46 %\n",
      "S1S2M0 :\t 554 \t 92.8 %\t 59.39 %\n",
      "S1S2T2 :\t 557 \t 93.3 %\t 49.73 %\n",
      "S1S2T1 :\t 564 \t 94.47 %\t 53.19 %\n",
      "S2T1T2M0 :\t 580 \t 97.15 %\t 42.93 %\n",
      "S1T1T2M0 :\t 577 \t 96.65 %\t 46.27 %\n",
      "S1S2T2M0 :\t 576 \t 96.48 %\t 44.44 %\n",
      "S1S2T1M0 :\t 580 \t 97.15 %\t 46.72 %\n",
      "S1S2T1T2 :\t 574 \t 96.15 %\t 43.9 %\n",
      "S1S2T1T2M0 :\t 585 \t 97.99 %\t 39.15 %\n"
     ]
    }
   ],
   "source": [
    "def Cal_Epoch_Combination(PL_List=[], Epoch_Combination=[], iter_index=0, Comb_List=[]):\n",
    "    if iter_index >= len(PL_List):\n",
    "        if Comb_List != []:\n",
    "            Epoch_Combination.append(Comb_List)\n",
    "        return\n",
    "    for available_out in PL_epoch_dict[PL_List[iter_index]]:\n",
    "        Comb_List_Next = Comb_List[:]\n",
    "        Comb_List_Next.append(available_out)\n",
    "        Cal_Epoch_Combination(PL_List, Epoch_Combination, iter_index+1, Comb_List_Next[:])\n",
    "    return Epoch_Combination\n",
    "\n",
    "for PL_List in Combination:\n",
    "    if len(PL_List)==1:\n",
    "        continue\n",
    "    Epoch_Combination_List = Cal_Epoch_Combination(PL_List, Epoch_Combination=[])\n",
    "    PLs = \"\".join(PL_List)\n",
    "    # print(\"\".join(PL_List),\"Epoch_Combination numbers:\",len(Epoch_Combination_List))\n",
    "    max_UB = 0\n",
    "    IoU = 0\n",
    "    for PLout_comb in Epoch_Combination_List:\n",
    "        UB = 0\n",
    "        overlap = 0\n",
    "        # logits path\n",
    "        logits_root_path_list = [\"./Logs/\"+part_id2str[part_id]+\"/\"+PL_ID+\"/Logits/\"+PL_Log_Dict[PL_ID]+\"/\" for PL_ID in PL_List]\n",
    "        # print(logits_root_path_list)\n",
    "        logits_path = []\n",
    "        for PL_index in range(len(PL_List)):  \n",
    "            logits_path.append(logits_root_path_list[PL_index]+str(PLout_comb[PL_index])+\".csv\")\n",
    "        # load logits\n",
    "        df_logits_list = [pd.read_csv(path, index_col=\"index\")[\"logits\"] for path in logits_path]\n",
    "        for df_logits in df_logits_list:\n",
    "            df_logits.sort_index(inplace=True)\n",
    "        # analyze logits\n",
    "        for index in range(len(label)):\n",
    "            logits_list = [np.array(df_logits_list[PL_index][index][1:-1].split(\",\")).astype(np.float_) for PL_index in range(len(df_logits_list))]\n",
    "            prediction = np.argmax(logits_list, axis=-1)\n",
    "            if np.isin(label[index], prediction):\n",
    "                UB += 1\n",
    "                _ = np.unique(prediction)\n",
    "                if len(_)==1:\n",
    "                    overlap += 1\n",
    "            if UB>max_UB:\n",
    "                max_UB = UB\n",
    "                IoU = overlap/UB\n",
    "    IoU *= 100\n",
    "    UB = max_UB\n",
    "    UBP = 100*max_UB/len(label)\n",
    "    print(PLs,\":\\t\",UB,\"\\t\",round(UBP,2),\"%\\t\",round(IoU,2),\"%\")\n",
    "    analyze_dict = {\"UB\":max_UB, \"UBP\":UBP, \"IoU\":IoU}\n",
    "    df_analyze = pd.DataFrame.from_dict(analyze_dict, orient=\"index\")\n",
    "    df_analyze.index.name = \"index\"\n",
    "    df_analyze.columns = [\"value\"]\n",
    "    df_analyze.to_csv(\"./Logs/\"+part_id2str[part_id]+\"/Analyze/Interflow/\"+class_nums2path[len(PL_List)]+\"/\"+PLs+\"_analyze.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average 10-flods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2M0 -->\tUB: 87.05 %\tIoU: 63.34 %\n",
      "T1M0 -->\tUB: 87.39 %\tIoU: 67.89 %\n",
      "T1T2 -->\tUB: 78.64 %\tIoU: 72.18 %\n",
      "S2M0 -->\tUB: 87.57 %\tIoU: 70.15 %\n",
      "S2T2 -->\tUB: 87.92 %\tIoU: 56.22 %\n",
      "S2T1 -->\tUB: 88.68 %\tIoU: 59.41 %\n",
      "S1M0 -->\tUB: 87.45 %\tIoU: 73.49 %\n",
      "S1T2 -->\tUB: 87.55 %\tIoU: 60.51 %\n",
      "S1T1 -->\tUB: 88.17 %\tIoU: 64.01 %\n",
      "S1S2 -->\tUB: 84.63 %\tIoU: 73.24 %\n",
      "T1T2M0 -->\tUB: 90.24 %\tIoU: 55.38 %\n",
      "S2T2M0 -->\tUB: 92.81 %\tIoU: 48.47 %\n",
      "S2T1M0 -->\tUB: 93.02 %\tIoU: 52.25 %\n",
      "S2T1T2 -->\tUB: 91.39 %\tIoU: 48.05 %\n",
      "S1T2M0 -->\tUB: 92.2 %\tIoU: 52.33 %\n",
      "S1T1M0 -->\tUB: 92.51 %\tIoU: 55.19 %\n",
      "S1T1T2 -->\tUB: 91.03 %\tIoU: 51.53 %\n",
      "S1S2M0 -->\tUB: 91.08 %\tIoU: 61.21 %\n",
      "S1S2T2 -->\tUB: 92.17 %\tIoU: 48.72 %\n",
      "S1S2T1 -->\tUB: 92.47 %\tIoU: 51.8 %\n",
      "S2T1T2M0 -->\tUB: 94.51 %\tIoU: 43.34 %\n",
      "S1T1T2M0 -->\tUB: 93.96 %\tIoU: 46.97 %\n",
      "S1S2T2M0 -->\tUB: 94.53 %\tIoU: 44.33 %\n",
      "S1S2T1M0 -->\tUB: 94.72 %\tIoU: 47.64 %\n",
      "S1S2T1T2 -->\tUB: 94.19 %\tIoU: 42.37 %\n",
      "S1S2T1T2M0 -->\tUB: 95.81 %\tIoU: 40.13 %\n"
     ]
    }
   ],
   "source": [
    "for PL_List in Combination:\n",
    "    if len(PL_List)==1:\n",
    "        continue\n",
    "    root_path_List = [\"./Logs/\"+part+\"/Analyze/Interflow/\"+class_nums2path[len(PL_List)]+\"/\" for part in part_List]\n",
    "    PLs = \"\".join(PL_List)\n",
    "    UBP_List = []\n",
    "    IoU_List = []\n",
    "    for root_path in root_path_List:\n",
    "        path = root_path+PLs+\"_analyze.csv\"\n",
    "        df_analyze = pd.read_csv(path, index_col=\"index\")\n",
    "        UBP_List.append(df_analyze.loc[\"UBP\"].to_numpy()[0])\n",
    "        IoU_List.append(df_analyze.loc[\"IoU\"].to_numpy()[0])\n",
    "    UBP_average = np.mean(UBP_List)\n",
    "    IoU_average = np.mean(IoU_List)\n",
    "    print(PLs,\"-->\\tUB:\",round(UBP_average,2),\"%\\tIoU:\",round(IoU_average,2),\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f18d1d36c0fabcb8b22250053d88db89962fe129b2054c2ee331cf33d9695e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
