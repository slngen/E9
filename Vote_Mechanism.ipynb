{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_id2str = {1:\"01F\",2:\"01M\",3:\"02F\",4:\"02M\",5:\"03F\",6:\"03M\",7:\"04F\",8:\"04M\",9:\"05F\",10:\"05M\"}\n",
    "part_id = 6\n",
    "label_path = \"./Data/iemocap/iemocap_\"+part_id2str[part_id]+\".test.csv\"\n",
    "'''\n",
    "formal:\n",
    "        dict:{PL_ID:Log_timestamp, ..., PL_ID:Log_timestamp},\n",
    "'''\n",
    "PL_Log_Dict = {\n",
    "        \"S1\":\"2022-05-02_18-59\",\n",
    "        \"S2\":\"2022-05-02_19-01\",\n",
    "        \"T1\":\"2022-05-02_17-12\",\n",
    "        \"T2\":\"2022-05-02_17-12\",\n",
    "        \"M0\":\"2022-05-02_18-03\",\n",
    "        }\n",
    "PL_Set_Size = 4\n",
    "epoch_nums = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'e0': 0, 'e1': 1, 'e2': 2, 'e3': 3}\n",
    "label = np.array(pd.read_csv(label_path)[\"emotion\"].map(lambda emo: label2id[emo]).values)\n",
    "print(\"load label done! total\",len(label),\"samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cal_Combination(iter_index=0, Comb_List=[]):\n",
    "    if iter_index >= len(PL_List):\n",
    "        if Comb_List!=[]:\n",
    "            Combination.append(Comb_List)\n",
    "        return\n",
    "    # not contain index element\n",
    "    Cal_Combination(iter_index+1, Comb_List[:])\n",
    "    # contain index element\n",
    "    Comb_List_Next = Comb_List[:]\n",
    "    Comb_List_Next.append(PL_List[iter_index])\n",
    "    Cal_Combination(iter_index+1, Comb_List_Next[:])\n",
    "\n",
    "PL_List = []\n",
    "for PL_ID in PL_Log_Dict.keys():\n",
    "    PL_List.append(PL_ID)\n",
    "Combination = []\n",
    "Cal_Combination()\n",
    "print(\"cal combination done! total\",len(Combination),\"combinations.\")\n",
    "# print(Combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synchro mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_decoder = {1:\"Baseline\", 2:\"2-Cross\", 3:\"3-Cross\", 4:\"4-Cross\", 5:\"5-Cross\"}\n",
    "# process one combination\n",
    "for PL_List in tqdm(Combination):\n",
    "    PL_nums = len(PL_List)\n",
    "    mode = part_id2str[part_id]+\"/\"+\"Analyze/Synchro/\"+mode_decoder[PL_nums]\n",
    "    combination_ID = \"\".join(PL_List)  # concat all PL-IDs, e.g. S1S2.\n",
    "    # logits path\n",
    "    logits_root_path_list = [\"./Logs/\"+part_id2str[part_id]+\"/\"+PL_ID+\"/Logits/\"+PL_Log_Dict[PL_ID]+\"/\" for PL_ID in PL_List]\n",
    "    # acc init\n",
    "    max_acc = 0\n",
    "    acc_result = []\n",
    "    for epoch in range(1,epoch_nums+1):\n",
    "        # acc init\n",
    "        acc_num = 0\n",
    "        # load logits\n",
    "        logits_path = [root_path+str(epoch)+\".csv\" for root_path in logits_root_path_list]\n",
    "        df_logits_list = [pd.read_csv(path, index_col=\"index\")[\"logits\"] for path in logits_path]\n",
    "        for df_logits in df_logits_list:\n",
    "            df_logits.sort_index(inplace=True)\n",
    "        # analyze logits\n",
    "        for index in range(len(label)):\n",
    "            logits_list = [np.array(df_logits_list[PL_index][index][1:-1].split(\",\")).astype(np.float_) for PL_index in range(len(df_logits_list))]\n",
    "            logits = np.zeros((4))\n",
    "            for _logits in logits_list:\n",
    "                logits += _logits\n",
    "            prediction = np.argmax(logits)\n",
    "            if label[index] == prediction:\n",
    "                acc_num += 1\n",
    "        acc = 100*acc_num/len(label)\n",
    "        max_acc = max(max_acc, acc)\n",
    "        acc_result.append(acc)\n",
    "    # logging\n",
    "    if not os.path.exists(\"./Logs/\"+mode+\"/\"):\n",
    "        os.makedirs(\"./Logs/\"+mode+\"/\")\n",
    "    df_acc_result = pd.DataFrame(acc_result, columns=[\"acc\"])\n",
    "    df_acc_result.to_csv(\"./Logs/\"+mode+\"/\"+combination_ID+\"_acc.txt\", index=False)\n",
    "    # plot\n",
    "    plt.figure(num=combination_ID, figsize=(8,5), dpi=100)\n",
    "    plt.title(mode_decoder[PL_nums]+\" \"+combination_ID+\"(\"+str(np.round(max_acc, 2))+\"%)\", fontsize=14)\n",
    "    plt.xlabel(\"epoch\", fontsize=14)\n",
    "    plt.ylabel(\"acc\", fontsize=14)\n",
    "    plt.plot(acc_result)\n",
    "    plt.savefig(\"./Logs/\"+mode+\"/\"+combination_ID+\".png\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interflow mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PLsets\n",
    "    each PL has one PLset in the PLsets, total N PLset.\n",
    "    each PLset has several PLout, total M PLout, and there is a \"minacc\" field to record the PLOuts' min acc,\n",
    "         in order to quickly decide.\n",
    "    each PLout identified by epoch_index and estimated by acc.\n",
    "    form as:\n",
    "        PLsets: {\n",
    "            PLset0:{\n",
    "                minacc:xx\n",
    "                PLout0:{epoch_index:xx,acc:xx},\n",
    "                PLout1:{epoch_index:xx,acc:xx},\n",
    "                ...\n",
    "                PLoutM:{epoch_index:xx,acc:xx}\n",
    "            },\n",
    "            ...\n",
    "            PLsetN:{\n",
    "                minacc:xx\n",
    "                PLout0:{epoch_index:xx,acc:xx},\n",
    "                PLout1:{epoch_index:xx,acc:xx},\n",
    "                ...\n",
    "                PLoutM:{epoch_index:xx,acc:xx}\n",
    "            },\n",
    "        }\n",
    "PLout only depends on eval acc alone. When there is a better PLout, it will replace the worst one.\n",
    "'''\n",
    "PLsets = {}\n",
    "'''\n",
    "PLoutUpdate\n",
    "    The newer PLout needs to calculate the new interflow acc. We use PLoutUpdate as the waiting queue.\n",
    "    e.g. \n",
    "        PLSet0 has updated the PLout10,\n",
    "        then we push \"(0,10)\" into PLoutUpdate as the meaning of PL0 had a newer PLout where its epoch_index is 10,\n",
    "        and need to calculate acc based on PLSet0:PLout10 with all other PLs' PLout.\n",
    "'''\n",
    "PLoutUpdate = []\n",
    "'''\n",
    "PLset_available_out\n",
    "record each PLout's epoch in distinguishing different PL way. \n",
    "this is what only required, then can further get epoch combination sequence and to calculate acc.\n",
    "e.g.\n",
    "    [\n",
    "        [PL0_epochxx,PL0_epochxx,PL0_epochxx,PL0_epochxx],  # the available PLouts' epoch_index of PL0\n",
    "        [PL1_epochxx],                                   # the available PLouts' epoch_index of PL1\n",
    "        ...\n",
    "    ]\n",
    "'''\n",
    "PLset_available_out = []\n",
    "'''\n",
    "Epoch_Combination\n",
    "the combination of all PLs' available out.\n",
    "combine the PLout from different PLset_available_out[PL_index].\n",
    "e.g.\n",
    "    [\n",
    "        [PL0_epochxx, PL1_epochxx, PL2_epochxx, ... , PLN_epochxx],\n",
    "        [PL0_epochxx, PL1_epochxx, PL2_epochxx, ... , PLN_epochxx],\n",
    "        ...\n",
    "    ]\n",
    "'''\n",
    "Epoch_Combination = []\n",
    "\n",
    "# multi thread temp\n",
    "acc_list = []\n",
    "thread_acc = None\n",
    "\n",
    "def Cal_Acc(update_PL_index, update_epoch, acc_list):\n",
    "    # init PLset_available_out\n",
    "    PLset_available_out = [[] for _ in range(len(PL_List))]\n",
    "    for PL_index in range(len(PL_List)):\n",
    "        if update_PL_index == PL_index:\n",
    "            PLset_available_out[PL_index].append(update_epoch)\n",
    "        else:\n",
    "            for PLout_index in range(1, len(PLsets[PL_index])):  # PLout_index=0 is \"accmin\" field\n",
    "                PLset_available_out[PL_index].append(PLsets[PL_index][PLout_index][\"epoch_index\"])\n",
    "    Epoch_Combination = Cal_Epoch_Combination(PLset_available_out, Epoch_Combination=[])\n",
    "    # cal acc\n",
    "    for PLout_comb in Epoch_Combination:\n",
    "        acc_num = 0\n",
    "        # logits path\n",
    "        logits_root_path_list = [\"./Logs/\"+part_id2str[part_id]+\"/\"+PL_ID+\"/Logits/\"+PL_Log_Dict[PL_ID]+\"/\" for PL_ID in PL_List]\n",
    "        logits_path = []\n",
    "        for PL_index in range(len(PL_List)):  \n",
    "            logits_path.append(logits_root_path_list[PL_index]+str(PLout_comb[PL_index])+\".csv\")\n",
    "        # load logits\n",
    "        df_logits_list = [pd.read_csv(path, index_col=\"index\")[\"logits\"] for path in logits_path]\n",
    "        for df_logits in df_logits_list:\n",
    "            df_logits.sort_index(inplace=True)\n",
    "        # analyze logits\n",
    "        for index in range(len(label)):\n",
    "            logits_list = [np.array(df_logits_list[PL_index][index][1:-1].split(\",\")).astype(np.float_) for PL_index in range(len(df_logits_list))]\n",
    "            logits = np.zeros((4))\n",
    "            for _logits in logits_list:\n",
    "                logits += _logits\n",
    "            prediction = np.argmax(logits)\n",
    "            if label[index] == prediction:\n",
    "                acc_num += 1\n",
    "        acc = 100*acc_num/len(label)\n",
    "        acc_list.append(acc)\n",
    "\n",
    "def Update_PLSets(epoch, df_dev_acc_list):\n",
    "    global PLsets\n",
    "    global PLoutUpdate\n",
    "    for PL_index, df_dev_acc in enumerate(df_dev_acc_list):\n",
    "        dev_acc = df_dev_acc.iloc[epoch-1, 0]  # dataframe index is start at 0.\n",
    "        # if PLset does not full, then just push.\n",
    "        if len(PLsets[PL_index]) <= PL_Set_Size:\n",
    "            PLsets[PL_index][len(PLsets[PL_index])] = {\"epoch_index\": epoch, \"acc\": dev_acc}\n",
    "            PLsets[PL_index][\"minacc\"] = min(PLsets[PL_index][\"minacc\"], dev_acc)\n",
    "            PLoutUpdate.append((PL_index, epoch))\n",
    "        else:\n",
    "            # if PLout is qualified go into PLset, the push, and replace the obsolete one.\n",
    "            if PLsets[PL_index][\"minacc\"] <= dev_acc:\n",
    "                obsolete_index = None\n",
    "                new_minacc = dev_acc\n",
    "                for PLout_index in range(1,PL_Set_Size+1):\n",
    "                    if PLsets[PL_index][PLout_index][\"acc\"] < new_minacc:\n",
    "                        new_minacc = PLsets[PL_index][PLout_index][\"acc\"]\n",
    "                        obsolete_index = PLout_index\n",
    "                # update\n",
    "                if obsolete_index != None:\n",
    "                    PLsets[PL_index][obsolete_index][\"epoch_index\"] = epoch\n",
    "                    PLsets[PL_index][obsolete_index][\"acc\"] = dev_acc\n",
    "                    PLsets[PL_index][\"minacc\"] = new_minacc\n",
    "                    PLoutUpdate.append((PL_index, epoch))\n",
    "\n",
    "def Cal_Epoch_Combination(PLset_available_out, Epoch_Combination=[], iter_index=0, Comb_List=[]):\n",
    "    if iter_index >= len(PL_List):\n",
    "        if Comb_List != []:\n",
    "            Epoch_Combination.append(Comb_List)\n",
    "        return\n",
    "    for available_out in PLset_available_out[iter_index]:\n",
    "        Comb_List_Next = Comb_List[:]\n",
    "        Comb_List_Next.append(available_out)\n",
    "        Cal_Epoch_Combination(PLset_available_out, Epoch_Combination, iter_index+1, Comb_List_Next[:])\n",
    "    return Epoch_Combination\n",
    "        \n",
    "def Update_Acc():\n",
    "    global PLsets\n",
    "    global PLoutUpdate\n",
    "    global acc_list\n",
    "    global thread_acc\n",
    "    acc_list = []\n",
    "    acc_max = 0\n",
    "    # check PLoutUpdate to recalculate acc.\n",
    "    while PLoutUpdate != []:\n",
    "        (update_PL_index, update_epoch) = PLoutUpdate.pop()\n",
    "        thread_acc = threading.Thread(target=Cal_Acc, args=(update_PL_index, update_epoch, acc_list))\n",
    "        thread_acc.start()\n",
    "    thread_acc.join()\n",
    "    for acc in acc_list:\n",
    "        acc_max = max(acc_max, acc)\n",
    "    return acc_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_decoder = {1:\"Baseline\", 2:\"2-Cross\", 3:\"3-Cross\", 4:\"4-Cross\", 5:\"5-Corss\"}\n",
    "# process one combination\n",
    "for PL_List in tqdm(Combination):\n",
    "    # init PL\n",
    "    PL_nums = len(PL_List)\n",
    "    for PL_index in range(PL_nums):\n",
    "        PLsets[PL_index] = {\"minacc\":float(\"inf\")}\n",
    "    mode = part_id2str[part_id]+\"/\"+\"Analyze/Interflow/\"+mode_decoder[PL_nums]\n",
    "    combination_ID = \"\".join(PL_List)  # concat all PL-IDs, e.g. S1S2.\n",
    "    # dev_acc path\n",
    "    dev_acc_path_list = [\"./Logs/\"+part_id2str[part_id]+\"/\"+PL_ID+\"/\"+PL_Log_Dict[PL_ID]+\"_dev_acc.txt\" for PL_ID in PL_List]\n",
    "    # dev_acc\n",
    "    df_dev_acc_list = [pd.read_csv(path, header=None) for path in dev_acc_path_list]\n",
    "    # acc init\n",
    "    max_acc = 0\n",
    "    acc_result = []\n",
    "    for epoch in range(1,epoch_nums+1):\n",
    "        # update PLsets\n",
    "        Update_PLSets(epoch, df_dev_acc_list)\n",
    "        # update acc\n",
    "        acc = Update_Acc()\n",
    "        max_acc = max(max_acc, acc)\n",
    "        acc_result.append(max_acc)\n",
    "    # logging\n",
    "    if not os.path.exists(\"./Logs/\"+mode+\"/\"):\n",
    "        os.makedirs(\"./Logs/\"+mode+\"/\")\n",
    "    df_acc_result = pd.DataFrame(acc_result, columns=[\"acc\"])\n",
    "    df_acc_result.to_csv(\"./Logs/\"+mode+\"/\"+combination_ID+\"_acc.txt\", index=False)\n",
    "    # plot\n",
    "    plt.figure(num=combination_ID, figsize=(8,5), dpi=100)\n",
    "    plt.title(mode_decoder[PL_nums]+\" \"+combination_ID+\"(\"+str(np.round(max_acc, 2))+\"%)\", fontsize=14)\n",
    "    plt.xlabel(\"epoch\", fontsize=14)\n",
    "    plt.ylabel(\"acc\", fontsize=14)\n",
    "    plt.plot(acc_result)\n",
    "    plt.savefig(\"./Logs/\"+mode+\"/\"+combination_ID+\".png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f18d1d36c0fabcb8b22250053d88db89962fe129b2054c2ee331cf33d9695e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
